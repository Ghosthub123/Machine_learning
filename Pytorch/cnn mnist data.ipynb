{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as dp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"PYTORCH_NOTEBOOKS/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = datasets.MNIST(root = path , train = True,transform = transform)\n",
    "x_test = datasets.MNIST(root = path , train = False , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(x_train,batch_size = 10,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(x_test,batch_size = 10,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1,6,3,1)\n",
    "conv2 = nn.Conv2d(6,16,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , (x_t,y_t )in enumerate(x_train):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_t.view(1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.max_pool2d(x,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.max_pool2d(x,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((28-2)/2)-2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(-1,16*5*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvolutionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,3,1)\n",
    "        self.conv2 = nn.Conv2d(6,16,3,1)\n",
    "        self.fc1 = nn.Linear(5*5*16,720)\n",
    "        self.fc2 = nn.Linear(720,80)\n",
    "        self.fc3 = nn.Linear(80,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        x = x.view(-1,5*5*16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x,dim = 1)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionModel(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=720, bias=True)\n",
       "  (fc2): Linear(in_features=720, out_features=80, bias=True)\n",
       "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "6\n",
      "864\n",
      "16\n",
      "288000\n",
      "720\n",
      "57600\n",
      "80\n",
      "800\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "criterion  = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:  600 [  6000/60000]  loss: 0.19702342  accuracy:  79.867%\n",
      "epoch:  0  batch: 1200 [ 12000/60000]  loss: 0.01941127  accuracy:  86.783%\n",
      "epoch:  0  batch: 1800 [ 18000/60000]  loss: 0.07161964  accuracy:  89.722%\n",
      "epoch:  0  batch: 2400 [ 24000/60000]  loss: 0.05725450  accuracy:  91.325%\n",
      "epoch:  0  batch: 3000 [ 30000/60000]  loss: 0.03065458  accuracy:  92.327%\n",
      "epoch:  0  batch: 3600 [ 36000/60000]  loss: 0.00127158  accuracy:  93.111%\n",
      "epoch:  0  batch: 4200 [ 42000/60000]  loss: 0.00394788  accuracy:  93.655%\n",
      "epoch:  0  batch: 4800 [ 48000/60000]  loss: 0.34566808  accuracy:  94.108%\n",
      "epoch:  0  batch: 5400 [ 54000/60000]  loss: 0.00153218  accuracy:  94.481%\n",
      "epoch:  0  batch: 6000 [ 60000/60000]  loss: 0.00268220  accuracy:  94.818%\n",
      "epoch:  1  batch:  600 [  6000/60000]  loss: 0.37970442  accuracy:  97.917%\n",
      "epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.00094762  accuracy:  97.825%\n",
      "epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.00230618  accuracy:  97.906%\n",
      "epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.00170437  accuracy:  97.921%\n",
      "epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.03309563  accuracy:  97.930%\n",
      "epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.00961274  accuracy:  98.003%\n",
      "epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.00141066  accuracy:  98.048%\n",
      "epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.00064269  accuracy:  98.065%\n",
      "epoch:  1  batch: 5400 [ 54000/60000]  loss: 0.00215133  accuracy:  98.096%\n",
      "epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.00456085  accuracy:  98.092%\n",
      "epoch:  2  batch:  600 [  6000/60000]  loss: 0.00118645  accuracy:  98.733%\n",
      "epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.03261086  accuracy:  98.783%\n",
      "epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.00061251  accuracy:  98.711%\n",
      "epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.16415790  accuracy:  98.717%\n",
      "epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.00010891  accuracy:  98.730%\n",
      "epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.01557482  accuracy:  98.750%\n",
      "epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.44687453  accuracy:  98.729%\n",
      "epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.00763771  accuracy:  98.737%\n",
      "epoch:  2  batch: 5400 [ 54000/60000]  loss: 0.00594092  accuracy:  98.741%\n",
      "epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.00098543  accuracy:  98.732%\n",
      "epoch:  3  batch:  600 [  6000/60000]  loss: 0.00524689  accuracy:  99.100%\n",
      "epoch:  3  batch: 1200 [ 12000/60000]  loss: 0.00052220  accuracy:  99.058%\n",
      "epoch:  3  batch: 1800 [ 18000/60000]  loss: 0.00332653  accuracy:  99.011%\n",
      "epoch:  3  batch: 2400 [ 24000/60000]  loss: 0.00390880  accuracy:  99.029%\n",
      "epoch:  3  batch: 3000 [ 30000/60000]  loss: 0.00066622  accuracy:  98.987%\n",
      "epoch:  3  batch: 3600 [ 36000/60000]  loss: 0.01990413  accuracy:  99.000%\n",
      "epoch:  3  batch: 4200 [ 42000/60000]  loss: 0.00042662  accuracy:  98.993%\n",
      "epoch:  3  batch: 4800 [ 48000/60000]  loss: 0.02092598  accuracy:  98.987%\n",
      "epoch:  3  batch: 5400 [ 54000/60000]  loss: 0.00177626  accuracy:  99.011%\n",
      "epoch:  3  batch: 6000 [ 60000/60000]  loss: 0.00146411  accuracy:  99.012%\n",
      "epoch:  4  batch:  600 [  6000/60000]  loss: 0.04253202  accuracy:  99.250%\n",
      "epoch:  4  batch: 1200 [ 12000/60000]  loss: 0.00002327  accuracy:  99.300%\n",
      "epoch:  4  batch: 1800 [ 18000/60000]  loss: 0.21429774  accuracy:  99.317%\n",
      "epoch:  4  batch: 2400 [ 24000/60000]  loss: 0.01835310  accuracy:  99.221%\n",
      "epoch:  4  batch: 3000 [ 30000/60000]  loss: 0.00016194  accuracy:  99.223%\n",
      "epoch:  4  batch: 3600 [ 36000/60000]  loss: 0.00025218  accuracy:  99.206%\n",
      "epoch:  4  batch: 4200 [ 42000/60000]  loss: 0.00164464  accuracy:  99.226%\n",
      "epoch:  4  batch: 4800 [ 48000/60000]  loss: 0.00004152  accuracy:  99.210%\n",
      "epoch:  4  batch: 5400 [ 54000/60000]  loss: 0.00006479  accuracy:  99.194%\n",
      "epoch:  4  batch: 6000 [ 60000/60000]  loss: 0.00004456  accuracy:  99.163%\n",
      "\n",
      "Duration: 266 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -4.3611e+01, -2.9384e+01, -4.0632e+01, -3.9588e+01,\n",
       "         -3.1817e+01, -2.9050e+01, -3.0303e+01, -2.8325e+01, -2.3304e+01],\n",
       "        [-3.1532e+01,  0.0000e+00, -2.6375e+01, -4.2028e+01, -2.6840e+01,\n",
       "         -3.3386e+01, -3.2263e+01, -2.0107e+01, -2.3225e+01, -2.3301e+01],\n",
       "        [-1.6709e+01, -1.8759e+01, -1.5648e+01, -1.3461e+01, -9.2048e+00,\n",
       "         -1.3398e+01, -1.7817e+01, -9.9848e+00, -8.9437e+00, -2.8046e-04],\n",
       "        [-3.2101e+01, -2.6881e+01, -1.9084e+01, -1.8302e+01, -2.4184e+01,\n",
       "         -2.4941e+01, -4.1236e+01,  0.0000e+00, -2.5854e+01, -2.3779e+01],\n",
       "        [-1.2974e+01, -1.4388e+01, -9.7388e+00, -1.0088e+01, -1.1920e+01,\n",
       "         -1.1319e+01, -1.2898e+01, -1.2368e+01, -1.6390e-04, -1.0266e+01],\n",
       "        [-1.8523e+01, -2.0401e+01, -1.6456e+01, -1.4865e+01, -1.7390e+01,\n",
       "         -1.4277e+01, -1.7097e+01, -1.9208e+01, -1.1921e-06, -1.6231e+01],\n",
       "        [-1.7666e+01, -2.1497e+01, -2.3693e+01, -2.7442e+01, -1.7967e+01,\n",
       "         -1.8525e+01,  0.0000e+00, -3.7411e+01, -2.2894e+01, -3.0295e+01],\n",
       "        [-3.2391e+01, -3.3292e+01,  0.0000e+00, -2.4339e+01, -3.2122e+01,\n",
       "         -3.4036e+01, -3.4370e+01, -3.1041e+01, -2.7732e+01, -3.9738e+01],\n",
       "        [-2.9012e+01, -2.2768e+01, -1.7362e+01, -2.0252e+01, -1.9964e+01,\n",
       "         -2.1635e+01, -3.4891e+01,  0.0000e+00, -2.3942e+01, -1.9415e+01],\n",
       "        [-2.6419e+01, -2.9297e+01, -2.1191e+01, -1.7219e+01, -2.4768e+01,\n",
       "         -1.8884e+01, -2.1546e+01, -2.7109e+01,  0.0000e+00, -2.4730e+01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
